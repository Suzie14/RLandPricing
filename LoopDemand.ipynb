{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sympy import symbols, diff, lambdify\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#Py files\n",
    "import multijoueurs_Q as multiQ\n",
    "import resultsPriceandProfits as res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = res.PriceOptimizer(nb_players=2)\n",
    "collusion_profit, collusion_price = prices.CollusionPrice()\n",
    "nash_profit, nash_price = prices.NashPrice()\n",
    "\n",
    "print(\"Collusion profit:\", collusion_profit, \"Collusion price:\", collusion_price)\n",
    "print(\"Nash profit:\",nash_profit, \"Nash price:\",nash_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collusion profit: 0.125 Collusion price: [1.5]\n",
      "Nash profit: 0.0 Nash price: [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "prices = res.PriceOptimizer(binary_demand=True)\n",
    "collusion_profit, collusion_price = prices.CollusionPrice()\n",
    "nash_profit, nash_price = prices.NashPrice()\n",
    "\n",
    "print(\"Collusion profit:\", collusion_profit, \"Collusion price:\", collusion_price)\n",
    "print(\"Nash profit:\",nash_profit, \"Nash price:\",nash_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 0\n",
      "Loop: 1\n",
      "Loop: 2\n",
      "Loop: 0\n",
      "Loop: 1\n",
      "Loop: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " # Changer le nombre de joueurs ici\n",
    "\n",
    "aggregated_agents = []\n",
    "for demand in [True, False]:\n",
    "    total_rewards = []\n",
    "\n",
    "    for loop in range(3):\n",
    "        print(\"Loop:\", loop)\n",
    "        agents = [multiQ.Agent(binary_demand=demand) for _ in range(2)]\n",
    "        env = multiQ.Env(binary_demand=demand)\n",
    "\n",
    "        temps = []\n",
    "        rewards = []\n",
    "        epsilon = []\n",
    "        prices = []\n",
    "\n",
    "        # Initialisation des prix p0 (on va le faire directement dans chaque agent)\n",
    "        for agent in agents:\n",
    "            agent.p = np.random.choice(agent.A)\n",
    "\n",
    "        # Initialisation de l'état\n",
    "        s_t = env([agent.p for agent in agents])[1]\n",
    "        for agent in agents:\n",
    "            agent.s_t = s_t\n",
    "\n",
    "        s_ind = agents[0].find_index(agents[0].S, agents[0].s_t)\n",
    "        for agent in agents:\n",
    "            agent.s_ind = s_ind\n",
    "\n",
    "        # Phase itérative\n",
    "        for t in range(10**4):\n",
    "            # Actions et état t+1\n",
    "            for agent in agents:\n",
    "                agent.a_ind = agent.get_next_action()\n",
    "\n",
    "            s_t1 = env([agent.A[agent.a_ind] for agent in agents])[1]\n",
    "            for agent in agents:\n",
    "                agent.s_t1 = s_t1\n",
    "\n",
    "            s_ind1 = agents[0].find_index(agents[0].S, agents[0].s_t1)\n",
    "            for agent in agents:\n",
    "                agent.s_ind1 = s_ind1\n",
    "\n",
    "            temps.append(t)\n",
    "            ret = env(s_t1)\n",
    "            quant, price, cost = ret\n",
    "\n",
    "            re = ret[0]*ret[1]-ret[0]*ret[2]\n",
    "            rewards.append(re)\n",
    "            epsilon_values = [agent.epsilon for agent in agents]\n",
    "            epsilon.append(epsilon_values)\n",
    "            prices.append([agent.p for agent in agents])\n",
    "\n",
    "            for i, agent in enumerate(agents):\n",
    "                agent.updateQ(q=quant[i], p=price[i], c=cost[i], t=t)\n",
    "\n",
    "        total_rewards.append(rewards)\n",
    "\n",
    "    aggregated_agents.append(np.array(total_rewards).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09316327,  0.01147959],\n",
       "        [ 0.03125   ,  0.16727041],\n",
       "        [-0.0175    ,  0.0805102 ],\n",
       "        ...,\n",
       "        [ 0.02415816,  0.0392602 ],\n",
       "        [ 0.02413265,  0.14336735],\n",
       "        [ 0.0057398 ,  0.10625   ]]),\n",
       " array([[0.28770967, 0.24139762],\n",
       "        [0.26320309, 0.34184172],\n",
       "        [0.25271541, 0.33527759],\n",
       "        ...,\n",
       "        [0.2163537 , 0.28421879],\n",
       "        [0.31148833, 0.32510304],\n",
       "        [0.33788134, 0.24178372]])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2216948057185367] [0.125, 0.3374904593213026]\n",
      "[[0.05156811 0.04831556]\n",
      " [0.28387555 0.27171283]]\n",
      "[[0.4125449  0.38652449]\n",
      " [0.53698686 0.43195078]]\n",
      "[0.39953469 0.48446882]\n",
      "Mean $\\Delta$ for binary demand: 0.3995346938775508\n",
      "Mean $\\Delta$ for 'exponential' demand: 0.48446881671395725\n"
     ]
    }
   ],
   "source": [
    "prices = res.PriceOptimizer(nb_players=2)\n",
    "collusion_profit, collusion_prices = prices.CollusionPrice()\n",
    "nash_profit, nash_prices = prices.NashPrice()\n",
    "\n",
    "prices_binary = res.PriceOptimizer(nb_players=2, binary_demand=True)\n",
    "collusion_profit_binary, collusion_prices_binary = prices_binary.CollusionPrice()\n",
    "nash_profit_binary, nash_prices_binary = prices_binary.NashPrice()\n",
    "\n",
    "RN = [nash_profit_binary, nash_profit]\n",
    "RC = [collusion_profit_binary, collusion_profit]\n",
    "    \n",
    "Rmean = np.zeros((len(aggregated_agents), 2))\n",
    "DRmean = np.zeros((len(aggregated_agents), 2))   \n",
    "    \n",
    "for i in range (len(aggregated_agents)): \n",
    "    for j in range (2):\n",
    "        Rmean[i][j] = aggregated_agents[i][-100:,j].mean()\n",
    "        DRmean[i][j] = (Rmean[i][j] - RN[i])/(RC[i] - RN[i]) \n",
    "\n",
    "print(RN, RC)\n",
    "print(Rmean)\n",
    "print(DRmean)\n",
    "\n",
    "av = np.mean(DRmean, axis=1)\n",
    "print(av)\n",
    "\n",
    "print(\"Mean $\\\\Delta$ for binary demand:\", av[0])\n",
    "print(\"Mean $\\\\Delta$ for 'exponential' demand:\", av[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
